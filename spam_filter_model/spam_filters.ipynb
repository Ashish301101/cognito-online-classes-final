{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv',delimiter=',',encoding='latin-1')\n",
    "del df[\"Unnamed: 2\"]\n",
    "del df[\"Unnamed: 3\"]\n",
    "del df[\"Unnamed: 4\"]\n",
    "df.columns = ['label','text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = [lemmatizer.lemmatize(word,pos=\"v\") for word in text.split() if word not in STOPWORDS]\n",
    "    text= ' '.join(text)\n",
    "    text = [lemmatizer.lemmatize(word,pos=\"a\") for word in text.split() if word not in STOPWORDS]\n",
    "    text= ' '.join(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    return text\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point  crazy available bugis n great...\n",
       "1                                 ok lar joking wif u oni\n",
       "2       free entry  wkly comp win fa cup final tkts st...\n",
       "3                     u dun say early hor u c already say\n",
       "4                  nah i think go usf  live around though\n",
       "                              ...                        \n",
       "5944                                                 yaoi\n",
       "5945                                        yellow shower\n",
       "5946                                                yiffy\n",
       "5947                                            zoophilia\n",
       "5948                                                     \n",
       "Name: text, Length: 5949, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.replace('\\d+', '')\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8114 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (5949, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (5949, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['label']).values\n",
    "print('Shape of label tensor:', Y.shape)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5354, 250) (5354, 2)\n",
      "(595, 250) (595, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 5,080,602\n",
      "Trainable params: 5,080,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "76/76 [==============================] - 74s 970ms/step - loss: 0.3602 - accuracy: 0.8551 - val_loss: 0.1738 - val_accuracy: 0.9086\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 83s 1s/step - loss: 0.0811 - accuracy: 0.9736 - val_loss: 0.1058 - val_accuracy: 0.9701\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 77s 1s/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.1078 - val_accuracy: 0.9664\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 76s 1s/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.1173 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 81s 1s/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1262 - val_accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "#model.fit(X_train,Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 50ms/step - loss: 0.0646 - accuracy: 0.9765\n",
      "Test set\n",
      "  Loss: 0.065\n",
      "  Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03150873 0.9684912 ]] spam\n"
     ]
    }
   ],
   "source": [
    "new_complaint = ['shit']\n",
    "new_complaint = [clean_text(new_complaint[0])]\n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "labels = ['ham','spam']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('spam_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11364656 0.8863535 ]] spam\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "models = load_model('spam_classifier.h5')\n",
    "\n",
    "new_complaint = ['fuck off']\n",
    "new_complaint = [clean_text(new_complaint[0])]\n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "labels = ['ham','spam']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding/embeddings:0' shape=(50000, 100) dtype=float32, numpy=\n",
       " array([[-0.03643825, -0.07546821,  0.09804107, ..., -0.04415632,\n",
       "         -0.09394564,  0.00342683],\n",
       "        [ 0.00442739,  0.06300038, -0.03702718, ...,  0.02492158,\n",
       "          0.05203681, -0.06668912],\n",
       "        [-0.04261263,  0.06723834, -0.00900643, ..., -0.01918705,\n",
       "          0.07445677, -0.02190241],\n",
       "        ...,\n",
       "        [ 0.017804  ,  0.04536338, -0.01568151, ..., -0.03696734,\n",
       "          0.02097887,  0.00338512],\n",
       "        [ 0.02779299, -0.03373472,  0.04159513, ..., -0.03186712,\n",
       "          0.00074468,  0.00013179],\n",
       "        [ 0.02618251, -0.0059527 ,  0.00331489, ...,  0.03223563,\n",
       "         -0.03865696,  0.02071199]], dtype=float32)>,\n",
       " <tf.Variable 'lstm/lstm_cell_2/kernel:0' shape=(100, 400) dtype=float32, numpy=\n",
       " array([[ 0.00725064,  0.08192713,  0.02255873, ...,  0.09886636,\n",
       "         -0.0723936 ,  0.02858222],\n",
       "        [ 0.12658955,  0.08196021,  0.09211063, ...,  0.08329953,\n",
       "          0.08700854,  0.05055236],\n",
       "        [-0.1516879 ,  0.03229096, -0.1208778 , ..., -0.04600206,\n",
       "          0.01405538, -0.05303865],\n",
       "        ...,\n",
       "        [ 0.03345216, -0.03410933,  0.00171534, ..., -0.07111318,\n",
       "         -0.0493333 , -0.01410331],\n",
       "        [-0.04339141, -0.07349851,  0.10089637, ...,  0.0650965 ,\n",
       "          0.00746397,  0.10439748],\n",
       "        [-0.12389919, -0.06243411,  0.11614906, ...,  0.06246742,\n",
       "         -0.1370165 , -0.10103503]], dtype=float32)>,\n",
       " <tf.Variable 'lstm/lstm_cell_2/recurrent_kernel:0' shape=(100, 400) dtype=float32, numpy=\n",
       " array([[ 0.04082068, -0.02829204,  0.01690421, ...,  0.01205989,\n",
       "          0.06790397, -0.00277831],\n",
       "        [ 0.02757625,  0.08001365,  0.00077144, ..., -0.04241617,\n",
       "          0.02870985,  0.03776082],\n",
       "        [-0.02715494,  0.0714424 , -0.02264681, ...,  0.10667547,\n",
       "         -0.03563984,  0.00055268],\n",
       "        ...,\n",
       "        [-0.0432731 ,  0.01779884, -0.04419913, ..., -0.03524017,\n",
       "         -0.01371243, -0.03529937],\n",
       "        [ 0.06664534,  0.12395071, -0.00081331, ..., -0.05718558,\n",
       "         -0.01431338,  0.03206609],\n",
       "        [-0.14206667, -0.02796796, -0.03347397, ...,  0.12485636,\n",
       "         -0.0480102 ,  0.00143014]], dtype=float32)>,\n",
       " <tf.Variable 'lstm/lstm_cell_2/bias:0' shape=(400,) dtype=float32, numpy=\n",
       " array([ 2.41539720e-02,  9.04495828e-03,  1.80485863e-02,  6.14921562e-02,\n",
       "         4.17803228e-02,  1.84459286e-03,  2.21437626e-02,  3.26044299e-02,\n",
       "         4.71915938e-02,  8.99161175e-02,  4.89840023e-02,  5.53346425e-02,\n",
       "         2.66456939e-02,  5.82659952e-02,  6.14596307e-02,  8.95371474e-03,\n",
       "        -3.48280510e-03,  3.60551849e-02,  7.99645782e-02,  5.64578064e-02,\n",
       "         1.76532920e-02,  6.22895360e-02,  9.09010172e-02,  5.38446233e-02,\n",
       "         6.18432984e-02,  7.85417855e-02,  2.42765043e-02,  3.97107080e-02,\n",
       "         8.39383900e-02,  4.44015972e-02,  2.08332390e-02,  2.44707614e-02,\n",
       "         7.40806609e-02,  5.89822643e-02,  8.29320997e-02,  3.05833612e-02,\n",
       "         2.48603001e-02,  4.24385555e-02,  3.46736386e-02,  8.42516646e-02,\n",
       "         4.27143313e-02,  3.09360214e-02,  3.32795866e-02,  2.30732914e-02,\n",
       "         9.37338397e-02,  1.21993221e-01,  3.01381871e-02,  1.16579738e-02,\n",
       "         2.44076755e-02,  2.21750103e-02,  3.69758010e-02,  3.27612534e-02,\n",
       "         9.10272473e-04,  8.17784015e-03,  1.75617132e-02,  4.87024672e-02,\n",
       "         3.10496576e-02,  1.24013938e-01,  6.46251440e-02,  1.09085076e-01,\n",
       "         5.07567376e-02,  1.34668082e-01,  3.97030860e-02,  8.73127058e-02,\n",
       "         6.75738677e-02,  1.06049217e-02,  1.08945951e-01,  1.85413472e-02,\n",
       "         2.77816728e-02,  1.37577593e-01,  9.28920954e-02,  8.55049770e-03,\n",
       "         5.83533384e-02,  6.22495413e-02,  8.86166692e-02,  1.31436400e-02,\n",
       "         3.21100727e-02,  1.38771221e-01,  3.13927867e-02,  1.87812913e-02,\n",
       "         4.47148867e-02,  7.26204291e-02,  7.39752082e-03,  4.42576334e-02,\n",
       "         1.86237246e-02,  2.34886743e-02,  1.78292990e-02,  6.01322018e-02,\n",
       "         1.82863828e-02,  1.02840327e-01,  2.09879577e-02,  7.13485926e-02,\n",
       "         3.60090062e-02,  1.03291191e-01,  3.01814880e-02,  4.15470526e-02,\n",
       "         1.90875493e-02,  2.16232967e-02,  2.55227890e-02,  9.89066586e-02,\n",
       "         9.94456053e-01,  9.86969411e-01,  1.00790870e+00,  1.00318623e+00,\n",
       "         1.00337029e+00,  9.81279731e-01,  9.98695314e-01,  1.00860715e+00,\n",
       "         1.01900363e+00,  1.00149155e+00,  9.94487941e-01,  1.02810717e+00,\n",
       "         1.00879884e+00,  1.03057182e+00,  1.04491997e+00,  9.92774725e-01,\n",
       "         9.90954518e-01,  1.02387071e+00,  1.01690805e+00,  1.00545001e+00,\n",
       "         1.00789893e+00,  1.00891590e+00,  1.01774538e+00,  1.01286221e+00,\n",
       "         1.00534892e+00,  1.01191568e+00,  1.01326323e+00,  1.01307392e+00,\n",
       "         1.02016902e+00,  1.00523031e+00,  1.00259256e+00,  1.00435686e+00,\n",
       "         1.02580118e+00,  9.98530746e-01,  1.01870644e+00,  1.01669359e+00,\n",
       "         9.98078823e-01,  9.96023655e-01,  1.00933623e+00,  1.03195763e+00,\n",
       "         1.02361906e+00,  9.87050772e-01,  9.98342335e-01,  1.00987351e+00,\n",
       "         1.01070035e+00,  1.02348900e+00,  1.00923252e+00,  1.00522864e+00,\n",
       "         1.00113988e+00,  1.00361741e+00,  1.01206386e+00,  1.01541162e+00,\n",
       "         9.64160979e-01,  9.90213633e-01,  9.86825347e-01,  1.01124012e+00,\n",
       "         1.00657201e+00,  1.00965023e+00,  1.00487792e+00,  1.01510108e+00,\n",
       "         1.02106845e+00,  1.03103924e+00,  9.98379588e-01,  1.00238943e+00,\n",
       "         1.02370727e+00,  1.00184560e+00,  1.00064099e+00,  1.00773346e+00,\n",
       "         1.01308632e+00,  1.02469218e+00,  1.01229107e+00,  9.98623371e-01,\n",
       "         1.00104344e+00,  1.01321602e+00,  1.03125679e+00,  1.00313354e+00,\n",
       "         1.00861752e+00,  1.02895117e+00,  1.01036429e+00,  1.00360513e+00,\n",
       "         1.01399255e+00,  1.01247013e+00,  9.98315215e-01,  9.91299212e-01,\n",
       "         1.00493217e+00,  9.91119862e-01,  1.00749707e+00,  1.02483261e+00,\n",
       "         1.01205432e+00,  1.04833651e+00,  1.00737941e+00,  1.01239729e+00,\n",
       "         9.88874912e-01,  1.01908159e+00,  1.01251805e+00,  1.01013505e+00,\n",
       "         1.00316310e+00,  1.00844336e+00,  9.89785016e-01,  1.01102829e+00,\n",
       "        -1.15668103e-02, -5.17948624e-03,  6.67546317e-03, -5.99972345e-03,\n",
       "        -3.32332253e-02,  9.97668481e-04, -1.93127594e-03, -3.50883859e-03,\n",
       "         2.53017470e-02,  3.10117472e-02,  3.32867019e-02,  4.85725105e-02,\n",
       "        -1.20099233e-02,  5.84900305e-02, -1.82566755e-02,  2.35314760e-02,\n",
       "         1.25311930e-02, -2.73656729e-03,  1.34251686e-03,  7.97730964e-03,\n",
       "        -7.87564903e-04,  4.03249357e-03, -1.21706724e-03,  3.67738819e-03,\n",
       "        -3.45850065e-02,  2.22107675e-03,  2.31032594e-04,  9.64264106e-03,\n",
       "         1.37837813e-03, -1.82590890e-03, -3.03191543e-02,  7.67618418e-03,\n",
       "         5.69314370e-03,  1.23865642e-02,  1.68330427e-02, -2.21154373e-02,\n",
       "        -5.34219760e-03, -4.95728385e-03, -3.51416180e-03, -4.23088763e-03,\n",
       "        -4.14613113e-02, -1.22552796e-03,  1.07100361e-03,  2.30829441e-03,\n",
       "        -9.42566618e-03, -2.87765376e-02, -5.54980990e-03, -3.62447719e-03,\n",
       "         1.59544870e-02, -1.69249903e-02, -5.52664977e-03,  2.68158037e-03,\n",
       "         2.02725548e-02, -2.36086119e-02,  4.04268950e-02, -4.81556868e-03,\n",
       "         1.95034081e-03, -6.96680928e-03,  4.64268029e-02,  2.10295594e-03,\n",
       "        -1.39307249e-02, -4.57847200e-05,  6.33958552e-05,  1.83375590e-02,\n",
       "        -6.61417283e-03,  1.25980773e-03,  3.32871415e-02, -1.14020659e-03,\n",
       "        -1.19998574e-03, -1.58368200e-02,  2.24327259e-02,  1.22997481e-02,\n",
       "        -3.46799218e-03,  1.55453766e-02,  9.92598757e-03,  4.72592283e-03,\n",
       "         5.41965012e-03,  2.41489001e-02,  2.58193864e-03,  1.77286461e-03,\n",
       "        -2.17501423e-03,  4.97381901e-03, -1.44944973e-02,  2.99412315e-03,\n",
       "        -9.10511299e-04,  2.08724174e-03,  2.08212208e-04, -1.53525211e-02,\n",
       "        -7.61587732e-03,  5.21875285e-02, -2.23566731e-03, -4.39147279e-03,\n",
       "        -5.29213622e-02,  5.16860932e-03, -1.43064875e-02, -6.43005408e-03,\n",
       "         2.08296115e-03,  6.74473122e-03,  2.45081484e-02,  1.77543033e-02,\n",
       "         2.31739599e-02,  3.30805592e-03,  1.92240570e-02,  6.40560612e-02,\n",
       "         3.61099392e-02,  2.61539128e-03,  1.52837606e-02,  2.79863961e-02,\n",
       "         4.75104414e-02,  8.48213285e-02,  4.25640568e-02,  4.78958748e-02,\n",
       "         2.74701621e-02,  4.67316397e-02,  6.44035265e-02,  8.31374340e-03,\n",
       "        -4.62715328e-03,  3.09926905e-02,  7.94032365e-02,  5.55811226e-02,\n",
       "         1.36724757e-02,  6.09397441e-02,  8.26695785e-02,  5.02567217e-02,\n",
       "         4.61352281e-02,  7.70189017e-02,  1.70433819e-02,  3.79200913e-02,\n",
       "         6.86293989e-02,  4.63375747e-02,  1.92639269e-02,  2.28568390e-02,\n",
       "         7.72604346e-02,  5.68303242e-02,  8.14962238e-02,  2.35658940e-02,\n",
       "         1.72859747e-02,  3.96498442e-02,  3.41248550e-02,  7.38259554e-02,\n",
       "         3.74866389e-02,  3.15094553e-02,  2.51442716e-02,  1.98841207e-02,\n",
       "         9.66234580e-02,  1.16180539e-01,  2.55520865e-02,  6.88278256e-03,\n",
       "         2.10657641e-02,  1.95207763e-02,  3.77373174e-02,  2.02915799e-02,\n",
       "        -3.17014358e-03,  5.42013813e-03,  1.19439354e-02,  4.57706638e-02,\n",
       "         2.94192452e-02,  1.25335515e-01,  4.41742875e-02,  1.11449718e-01,\n",
       "         4.33153063e-02,  1.31605640e-01,  3.64166535e-02,  7.81186521e-02,\n",
       "         6.96535334e-02,  6.94263866e-03,  1.02877498e-01,  1.37797045e-02,\n",
       "         2.39518154e-02,  1.43296435e-01,  9.18798521e-02,  6.65148441e-03,\n",
       "         5.51618040e-02,  5.92984408e-02,  8.43760893e-02,  9.27644223e-03,\n",
       "         2.58401372e-02,  1.34738281e-01,  2.54668035e-02,  1.36254700e-02,\n",
       "         3.74841355e-02,  6.93502799e-02,  6.29265886e-03,  4.41075712e-02,\n",
       "         1.77675318e-02,  2.42348593e-02,  1.14282155e-02,  5.80492914e-02,\n",
       "         1.48824770e-02,  8.31250399e-02,  1.49739077e-02,  6.85740486e-02,\n",
       "         2.96943560e-02,  1.09136589e-01,  3.07537820e-02,  4.05866466e-02,\n",
       "         1.55919883e-02,  1.98997948e-02,  2.34009307e-02,  8.87196139e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(100, 2) dtype=float32, numpy=\n",
       " array([[-0.14885274,  0.15139744],\n",
       "        [ 0.00136436,  0.05724465],\n",
       "        [-0.01937358,  0.20053937],\n",
       "        [-0.27053905,  0.10945164],\n",
       "        [-0.28201342, -0.01229819],\n",
       "        [-0.13508666, -0.2034246 ],\n",
       "        [-0.10267615, -0.07254122],\n",
       "        [-0.24884449,  0.11442376],\n",
       "        [ 0.15555191, -0.11224515],\n",
       "        [ 0.14030069, -0.2764377 ],\n",
       "        [-0.0709843 , -0.18089995],\n",
       "        [ 0.0943794 , -0.11312064],\n",
       "        [-0.1578561 ,  0.15036006],\n",
       "        [ 0.05212082, -0.0859619 ],\n",
       "        [ 0.06457634, -0.13264942],\n",
       "        [-0.26085082, -0.15901144],\n",
       "        [ 0.05728871, -0.05072835],\n",
       "        [ 0.2842434 ,  0.07809004],\n",
       "        [ 0.21273208, -0.32807726],\n",
       "        [-0.29006064,  0.13497958],\n",
       "        [-0.07435244,  0.1881701 ],\n",
       "        [-0.20655191,  0.14438972],\n",
       "        [ 0.28163666, -0.28011844],\n",
       "        [-0.28554162,  0.05198551],\n",
       "        [-0.25323027, -0.07350984],\n",
       "        [ 0.31841084, -0.21591114],\n",
       "        [ 0.01548288, -0.22840865],\n",
       "        [ 0.2999532 , -0.17546074],\n",
       "        [-0.19735852,  0.20168896],\n",
       "        [-0.25843388,  0.11668961],\n",
       "        [ 0.19032699,  0.13195416],\n",
       "        [-0.03499231,  0.22031347],\n",
       "        [-0.3048675 ,  0.29465008],\n",
       "        [ 0.07055489, -0.3128946 ],\n",
       "        [-0.08172524,  0.17768228],\n",
       "        [ 0.28167552, -0.0218068 ],\n",
       "        [-0.0591715 , -0.11981242],\n",
       "        [ 0.313235  ,  0.06409508],\n",
       "        [-0.23149765,  0.2957977 ],\n",
       "        [ 0.38504735, -0.11639103],\n",
       "        [-0.17887712, -0.09007854],\n",
       "        [-0.01288777,  0.29447374],\n",
       "        [-0.17085135, -0.06374151],\n",
       "        [ 0.21548744, -0.28619003],\n",
       "        [-0.33736452,  0.29666036],\n",
       "        [-0.3037563 ,  0.31827328],\n",
       "        [-0.09647197,  0.18953565],\n",
       "        [-0.00974882,  0.05730438],\n",
       "        [-0.07344154, -0.11549603],\n",
       "        [-0.10105998,  0.02262043],\n",
       "        [-0.02343116, -0.271657  ],\n",
       "        [-0.04365497, -0.20541942],\n",
       "        [-0.06662271, -0.16404755],\n",
       "        [-0.16729967, -0.12838314],\n",
       "        [ 0.03653248, -0.11709484],\n",
       "        [ 0.14744647, -0.20539081],\n",
       "        [ 0.16361447, -0.20102617],\n",
       "        [ 0.27164724, -0.28525335],\n",
       "        [ 0.24055612, -0.14160839],\n",
       "        [ 0.3837864 , -0.17072965],\n",
       "        [ 0.06172301, -0.0488007 ],\n",
       "        [ 0.30209404, -0.32435182],\n",
       "        [ 0.2084895 , -0.16628566],\n",
       "        [ 0.18320976, -0.26115918],\n",
       "        [ 0.32000607, -0.29081738],\n",
       "        [-0.01775747, -0.00833022],\n",
       "        [ 0.25920245, -0.33273646],\n",
       "        [-0.17806408,  0.20011504],\n",
       "        [ 0.23273109, -0.30088913],\n",
       "        [-0.18308404,  0.24227867],\n",
       "        [ 0.35739875, -0.182091  ],\n",
       "        [-0.01578355,  0.19975047],\n",
       "        [-0.0331416 ,  0.31526974],\n",
       "        [ 0.312545  , -0.11120152],\n",
       "        [-0.31182846,  0.2967895 ],\n",
       "        [-0.13523568,  0.1666883 ],\n",
       "        [ 0.08829515, -0.20651777],\n",
       "        [ 0.24470466, -0.3397456 ],\n",
       "        [-0.19946587,  0.2437548 ],\n",
       "        [ 0.24337137,  0.06680082],\n",
       "        [-0.2358119 ,  0.19486953],\n",
       "        [ 0.32265934, -0.24415201],\n",
       "        [-0.094228  , -0.25369245],\n",
       "        [-0.2707209 , -0.07569391],\n",
       "        [ 0.21663922, -0.14084826],\n",
       "        [ 0.11185606,  0.01595829],\n",
       "        [-0.14513953, -0.15000504],\n",
       "        [ 0.33175159, -0.03064794],\n",
       "        [-0.17746659, -0.19543591],\n",
       "        [ 0.22992042, -0.08474637],\n",
       "        [ 0.0986736 ,  0.07554037],\n",
       "        [ 0.15232891, -0.33851957],\n",
       "        [-0.0542268 ,  0.27655846],\n",
       "        [ 0.3541114 , -0.37131125],\n",
       "        [ 0.07478512, -0.25295347],\n",
       "        [-0.14536749,  0.2854704 ],\n",
       "        [-0.15769073, -0.1812493 ],\n",
       "        [-0.07619883,  0.16296037],\n",
       "        [ 0.28911623, -0.01172588],\n",
       "        [ 0.2765822 , -0.11321401]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32, numpy=array([-0.00068039,  0.0006804 ], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('Tokenizer.pkl','wb')\n",
    "pickle.dump(tokenizer,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
